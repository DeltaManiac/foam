{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/producer","result":{"data":{"file":{"childMdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"producer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Producer\"), mdx(\"p\", null, \"Kafka has a binary wire protocol.This means that it is possible for applications to read messages from Kafka or write messages to Kafka simply by sending the correct byte sequences to Kafka\\u2019s network port.\"), mdx(\"p\", null, \"Key Structure is \", mdx(\"inlineCode\", {\n    \"parentName\": \"p\"\n  }, \"ProducerRecord\")), mdx(\"p\", null), mdx(\"h1\", {\n    \"id\": \"serializer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Serializer\"), mdx(\"p\", null, \"Converts between wire format and code\"), mdx(\"p\", null, mdx(\"a\", {\n    \"href\": \"https://https://avro.apache.org/docs/current\",\n    \"parentName\": \"p\"\n  }, \"Apache Avro\"), \"\\nDefine a common schema for serialization and deserialization\\nStore in schema Registry\\nStore schema identifier in produced message\\n\"), mdx(\"h1\", {\n    \"id\": \"creating-a-producer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Creating a Producer\"), mdx(\"h2\", {\n    \"id\": \"in-rust\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"In [\", mdx(\"a\", {\n    \"href\": \"rust\",\n    \"title\": \"Rust\",\n    \"parentName\": \"h2\"\n  }, \"rust\"), \"]\"), mdx(\"p\", null, \"Crate : \", mdx(\"a\", {\n    \"href\": \"https://crates.io/crates/kafka\",\n    \"parentName\": \"p\"\n  }, \"kafka\")), mdx(\"pre\", null, mdx(\"code\", {\n    \"className\": \"language-rust\",\n    \"parentName\": \"pre\"\n  }, \"/// Producer Code\\nuse std::fmt::Write;\\nuse std::time::Duration;\\nuse kafka::producer::{Producer, Record, RequiredAcks};\\n\\nlet mut producer = Producer::from_hosts(vec!(\\\"localhost:9092\\\".to_owned()))\\n.with_ack_timeout(Duration::from_secs(1))\\n.with_required_acks(RequiredAcks::One)\\n.create()\\n.unwrap();\\n\\nlet mut buf = String::with*capacity(2);\\nfor i in 0..10 {\\nlet * = write!(&mut buf, \\\"{}\\\", i); // some computation of the message data to be sent\\nproducer.send(&Record::from_value(\\\"my-topic\\\", buf.as_bytes())).unwrap();\\nbuf.clear();\\n}\\n\")), mdx(\"p\", null, \"Crate : \", mdx(\"a\", {\n    \"href\": \"https://crates.io/crates/rdkafka\",\n    \"parentName\": \"p\"\n  }, \"rdkafka\")), mdx(\"pre\", null, mdx(\"code\", {\n    \"className\": \"language-Rust\",\n    \"parentName\": \"pre\"\n  }, \" sync fn produce(brokers: &str, topic_name: &str) {\\n    let producer: &FutureProducer = &ClientConfig::new()\\n        .set(\\\"bootstrap.servers\\\", brokers)\\n        .set(\\\"message.timeout.ms\\\", \\\"5000\\\")\\n        .create()\\n        .expect(\\\"Producer creation error\\\");\\n\\n    // This loop is non blocking: all messages will be sent one after the other, without waiting\\n    // for the results.\\n    let futures = (0..5)\\n        .map(|i| async move {\\n            // The send operation on the topic returns a future, which will be\\n            // completed once the result or failure from Kafka is received.\\n            let delivery_status = producer\\n                .send(\\n                    FutureRecord::to(topic_name)\\n                        .payload(&format!(\\\"Message {}\\\", i))\\n                        .key(&format!(\\\"Key {}\\\", i))\\n                        .headers(OwnedHeaders::new().add(\\\"header_key\\\", \\\"header_value\\\")),\\n                    Duration::from_secs(0),\\n                )\\n                .await;\\n\\n            // This will be executed when the result is received.\\n            info!(\\\"Delivery status for message {} received\\\", i);\\n            delivery_status\\n        })\\n        .collect::<Vec<_>>();\\n\\n    // This loop will wait until all delivery statuses have been received.\\n    for future in futures {\\n        info!(\\\"Future completed. Result: {:?}\\\", future.await);\\n    }\\n}\\n\\n\")), mdx(\"p\", null, \"Schema Registry for confluent : \", mdx(\"a\", {\n    \"href\": \"https://github.com/gklijs/schema_registry_converter\",\n    \"parentName\": \"p\"\n  }, \"https://github.com/gklijs/schema_registry_converter\")), mdx(\"p\", null, \"Confluent Write up : \", mdx(\"a\", {\n    \"href\": \"https://www.confluent.io/blog/getting-started-with-rust-and-kafka/\",\n    \"parentName\": \"p\"\n  }, \"https://www.confluent.io/blog/getting-started-with-rust-and-kafka/\")), mdx(\"hr\", null), mdx(\"h2\", {\n    \"id\": \"in-golang\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"In [\", mdx(\"a\", {\n    \"href\": \"golang\",\n    \"title\": \"Golang\",\n    \"parentName\": \"h2\"\n  }, \"golang\"), \"]\"), mdx(\"p\", null, \"Package : \", mdx(\"a\", {\n    \"href\": \"https://github.com/confluentinc/confluent-kafka-go\",\n    \"parentName\": \"p\"\n  }, \"Confluent Inc\")), mdx(\"pre\", null, mdx(\"code\", {\n    \"className\": \"language-golang\",\n    \"parentName\": \"pre\"\n  }, \"func main() {\\n\\n    p, err := kafka.NewProducer(&kafka.ConfigMap{\\\"bootstrap.servers\\\": \\\"localhost\\\"})\\n    if err != nil {\\n        panic(err)\\n    }\\n\\n    defer p.Close()\\n\\n    // Delivery report handler for produced messages\\n    go func() {\\n        for e := range p.Events() {\\n            switch ev := e.(type) {\\n            case *kafka.Message:\\n                if ev.TopicPartition.Error != nil {\\n                    fmt.Printf(\\\"Delivery failed: %v\\\\n\\\", ev.TopicPartition)\\n                } else {\\n                    fmt.Printf(\\\"Delivered message to %v\\\\n\\\", ev.TopicPartition)\\n                }\\n            }\\n        }\\n    }()\\n\\n    // Produce messages to topic (asynchronously)\\n    topic := \\\"myTopic\\\"\\n    for _, word := range []string{\\\"Welcome\\\", \\\"to\\\", \\\"the\\\", \\\"Confluent\\\", \\\"Kafka\\\", \\\"Golang\\\", \\\"client\\\"} {\\n        p.Produce(&kafka.Message{\\n            TopicPartition: kafka.TopicPartition{Topic: &topic, Partition: kafka.PartitionAny},\\n            Value:          []byte(word),\\n        }, nil)\\n    }\\n\\n    // Wait for message deliveries before shutting down\\n    p.Flush(15 * 1000)\\n}\\n\")), mdx(\"p\", null, \"Package : \", mdx(\"a\", {\n    \"href\": \"https://github.com/segmentio/kafka-go\",\n    \"parentName\": \"p\"\n  }, \"SegmentIO\")), mdx(\"pre\", null, mdx(\"code\", {\n    \"className\": \"language-golang\",\n    \"parentName\": \"pre\"\n  }, \"func producer() {\\n\\n    topic := \\\"my-topic\\\"\\n    partition := 0\\n\\n    conn, _ := kafka.DialLeader(context.Background(), \\\"tcp\\\", \\\"localhost:9092\\\", topic, partition)\\n\\n    conn.SetWriteDeadline(time.Now().Add(10*time.Second))\\n    conn.WriteMessages(\\n    kafka.Message{Value: []byte(\\\"one!\\\")},\\n    kafka.Message{Value: []byte(\\\"two!\\\")},\\n    kafka.Message{Value: []byte(\\\"three!\\\")},\\n    )\\n\\n    conn.Close()\\n}\\n\")), mdx(\"p\", null, \"Package : \", mdx(\"a\", {\n    \"href\": \"https://github.com/Shopify/sarama\",\n    \"parentName\": \"p\"\n  }, \"Sarama\")), mdx(\"pre\", null, mdx(\"code\", {\n    \"className\": \"language-golang\",\n    \"parentName\": \"pre\"\n  }, \"//Sync Producer\\nfunc newDataCollector(brokerList []string) sarama.SyncProducer {\\n\\n    // For the data collector, we are looking for strong consistency semantics.\\n    // Because we don't change the flush settings, sarama will try to produce messages\\n    // as fast as possible to keep latency low.\\n    config := sarama.NewConfig()\\n    config.Producer.RequiredAcks = sarama.WaitForAll // Wait for all in-sync replicas to ack the message\\n    config.Producer.Retry.Max = 10                   // Retry up to 10 times to produce the message\\n    config.Producer.Return.Successes = true\\n    tlsConfig := createTlsConfiguration()\\n    if tlsConfig != nil {\\n        config.Net.TLS.Config = tlsConfig\\n        config.Net.TLS.Enable = true\\n    }\\n\\n    // On the broker side, you may want to change the following settings to get\\n    // stronger consistency guarantees:\\n    // - For your broker, set `unclean.leader.election.enable` to false\\n    // - For the topic, you could increase `min.insync.replicas`.\\n\\n    producer, err := sarama.NewSyncProducer(brokerList, config)\\n    if err != nil {\\n        log.Fatalln(\\\"Failed to start Sarama producer:\\\", err)\\n    }\\n\\n    return producer\\n}\\n\\n// Async Producer\\nfunc newAccessLogProducer(brokerList []string) sarama.AsyncProducer {\\n\\n    // For the access log, we are looking for AP semantics, with high throughput.\\n    // By creating batches of compressed messages, we reduce network I/O at a cost of more latency.\\n    config := sarama.NewConfig()\\n    tlsConfig := createTlsConfiguration()\\n    if tlsConfig != nil {\\n        config.Net.TLS.Enable = true\\n        config.Net.TLS.Config = tlsConfig\\n    }\\n    config.Producer.RequiredAcks = sarama.WaitForLocal       // Only wait for the leader to ack\\n    config.Producer.Compression = sarama.CompressionSnappy   // Compress messages\\n    config.Producer.Flush.Frequency = 500 * time.Millisecond // Flush batches every 500ms\\n\\n    producer, err := sarama.NewAsyncProducer(brokerList, config)\\n    if err != nil {\\n        log.Fatalln(\\\"Failed to start Sarama producer:\\\", err)\\n    }\\n\\n    // We will just log to STDOUT if we're not able to produce messages.\\n    // Note: messages will only be returned here after all retry attempts are exhausted.\\n    go func() {\\n        for err := range producer.Errors() {\\n            log.Println(\\\"Failed to write access log entry:\\\", err)\\n        }\\n    }()\\n\\n    return producer\\n}\\n\\ngo func sendMessage(){\\n        // Synch\\n        partition, offset, err := s.DataCollector.SendMessage(&sarama.ProducerMessage{\\n            Topic: \\\"important\\\",\\n            Value: sarama.StringEncoder(r.URL.RawQuery),\\n        })\\n        // Async\\n        s.AccessLogProducer.Input() <- &sarama.ProducerMessage{\\n            Topic: \\\"access_log\\\",\\n            Key:   sarama.StringEncoder(r.RemoteAddr),\\n            Value: entry,\\n        }\\n}\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"rust\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Rust\"), mdx(\"h2\", {\n    \"id\": \"reddit-bot\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Reddit Bot\"), mdx(\"p\", null, \"VyomBot \", mdx(\"a\", {\n    \"href\": \"/vyom\",\n    \"title\": \"vyom\",\n    \"parentName\": \"p\"\n  }, \"[[vyom]]\"), \"\"), mdx(\"h2\", {\n    \"id\": \"kafka\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Kafka\"), mdx(\"p\", null, \"Kafka [\", mdx(\"a\", {\n    \"href\": \"producer\",\n    \"title\": \"Producer\",\n    \"parentName\": \"p\"\n  }, \"Producer\"), \"]\"), mdx(\"p\", null, \"Kafka [\", mdx(\"a\", {\n    \"href\": \"consumer\",\n    \"title\": \"Consumer\",\n    \"parentName\": \"p\"\n  }, \"Consumer\"), \"]\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"80160a7b-29c9-59fa-866f-c39ebab1da04","fields":{"slug":"/rust","title":"Rust"}}},{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"golang\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Golang\"), mdx(\"h2\", {\n    \"id\": \"web-dev\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Web Dev\"), mdx(\"p\", null, \"[\", mdx(\"a\", {\n    \"href\": \"gokit\",\n    \"title\": \"Gokit\",\n    \"parentName\": \"p\"\n  }, \"gokit\"), \"]\"), mdx(\"h2\", {\n    \"id\": \"kafka\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Kafka\"), mdx(\"p\", null, \"Kafka [\", mdx(\"a\", {\n    \"href\": \"producer\",\n    \"title\": \"Producer\",\n    \"parentName\": \"p\"\n  }, \"producer\"), \"]\"), mdx(\"p\", null, \"Kafka [\", mdx(\"a\", {\n    \"href\": \"consumer\",\n    \"title\": \"Consumer\",\n    \"parentName\": \"p\"\n  }, \"consumer\"), \"]\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"c67dd331-477d-55b4-b7e1-c14bf357a00a","fields":{"slug":"/golang","title":"Golang"}}}],"inboundReferences":[{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"apache-kafka\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Apache Kafka\"), mdx(\"ul\", null, mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"pub-sub messaging system\")), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"basic unit --> message =>\", mdx(\"inlineCode\", {\n    \"parentName\": \"p\"\n  }, \"{ Body :[u8], Key:[u8]}\"))), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"writes are mainly batch operations => \", mdx(\"inlineCode\", {\n    \"parentName\": \"p\"\n  }, \"Vec<Messages>\"))), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"does not track acknowledgments from consumers but allows consumers to use Kafka to track their position (offset) in each partition.\")), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"Schema --> governs structure of message\"), mdx(\"ul\", {\n    \"parentName\": \"li\"\n  }, mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"eg JSON/XML/\", mdx(\"a\", {\n    \"href\": \"https://avro.apache.org/docs/current/\",\n    \"parentName\": \"li\"\n  }, \"Apache Avro\")))), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"Topics --> collection of messages \\\"about something same\\\"\")), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"Topics made of n partitions => Append only queue-like\"), mdx(\"p\", {\n    \"parentName\": \"li\"\n  })), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"Stream => Single topic of data irrespective of partitions\")), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"[\", mdx(\"a\", {\n    \"href\": \"producer\",\n    \"title\": \"Producer\",\n    \"parentName\": \"p\"\n  }, \"Producer\"), \"]\"), mdx(\"ul\", {\n    \"parentName\": \"li\"\n  }, mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"produce message for a topic, can sometimes specify which partition to store\"))), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"[\", mdx(\"a\", {\n    \"href\": \"consumer\",\n    \"title\": \"Consumer\",\n    \"parentName\": \"p\"\n  }, \"Consumer\"), \"]\"), mdx(\"ul\", {\n    \"parentName\": \"li\"\n  }, mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"Reads message\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"Subscribes 1:n topics\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"FIFO Read (Queue like)\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"track of consumed messages via offset\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"strong\", {\n    \"parentName\": \"li\"\n  }, \"Ownership\"), \" mapping of consumer to partitions\"))), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"Consumer Group -> 1 or more consumers that work together to consumer a topic\"), mdx(\"p\", {\n    \"parentName\": \"li\"\n  })), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"Kafka Broker -> Single Kafka server\"), mdx(\"ul\", {\n    \"parentName\": \"li\"\n  }, mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"Receives messages from Producers\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"Assign offset\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"Commit to disk\"))), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"Kafka Cluster\"), mdx(\"ul\", {\n    \"parentName\": \"li\"\n  }, mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"Collection of brokers\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"strong\", {\n    \"parentName\": \"li\"\n  }, \"1\"), \" automatically elected broker will function as the cluster \", mdx(\"strong\", {\n    \"parentName\": \"li\"\n  }, \"controller\")), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"Controller responsibilities\", mdx(\"ul\", {\n    \"parentName\": \"li\"\n  }, mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"administrative operations\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"assigning partitions to broker\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"monitor for broker failures\")))), mdx(\"p\", {\n    \"parentName\": \"li\"\n  })), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"Retention -> Configurable for a period of time or size of topic (GB/MB)\")), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, mdx(\"p\", {\n    \"parentName\": \"li\"\n  }, \"Kafka : Pitch\"), mdx(\"ul\", {\n    \"parentName\": \"li\"\n  }, mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"Multiple Producers x Multiple Topics\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"Multiple Consumers\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"Disk Based Retention --> No data loss\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"Scalable\"), mdx(\"li\", {\n    \"parentName\": \"ul\"\n  }, \"High Performance\")))), mdx(\"h2\", {\n    \"id\": \"starting-kafka-on-osx\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Starting Kafka on OSX\"), mdx(\"pre\", null, mdx(\"code\", {\n    \"className\": \"language-shell\",\n    \"parentName\": \"pre\"\n  }, \"# Start ZooKeeper\\n# `zkServer` DOESNT WORK IN TMUX!!!\\nzookeeper-server-start /usr/local/etc/kafka/zookeeper.properties & kafka-server-start /usr/local/etc/kafka/server.properties\\n\\n# Start kafka server\\nkafka-server-start.sh /usr/local/etc/kafka/server.properties\\n\\n# Create a topic\\nkafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic temptopic\\n\\n# Start a producer to temptopic\\nkafka-console-producer --broker-list localhost:9092 --topic temptopic\\n\\n# In another tab start a consumer to temptopic\\nkafka-console-producer --broker-list localhost:9092 --topic temptopic --from-beginning\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"1e7fcadb-7efc-56d0-a835-534146fc3704","fields":{"slug":"/kafka","title":"Apache Kafka"}}},{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"golang\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Golang\"), mdx(\"h2\", {\n    \"id\": \"web-dev\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Web Dev\"), mdx(\"p\", null, \"[\", mdx(\"a\", {\n    \"href\": \"gokit\",\n    \"title\": \"Gokit\",\n    \"parentName\": \"p\"\n  }, \"gokit\"), \"]\"), mdx(\"h2\", {\n    \"id\": \"kafka\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Kafka\"), mdx(\"p\", null, \"Kafka [\", mdx(\"a\", {\n    \"href\": \"producer\",\n    \"title\": \"Producer\",\n    \"parentName\": \"p\"\n  }, \"producer\"), \"]\"), mdx(\"p\", null, \"Kafka [\", mdx(\"a\", {\n    \"href\": \"consumer\",\n    \"title\": \"Consumer\",\n    \"parentName\": \"p\"\n  }, \"consumer\"), \"]\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"c67dd331-477d-55b4-b7e1-c14bf357a00a","fields":{"slug":"/golang","title":"Golang"}}},{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"rust\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Rust\"), mdx(\"h2\", {\n    \"id\": \"reddit-bot\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Reddit Bot\"), mdx(\"p\", null, \"VyomBot \", mdx(\"a\", {\n    \"href\": \"/vyom\",\n    \"title\": \"vyom\",\n    \"parentName\": \"p\"\n  }, \"[[vyom]]\"), \"\"), mdx(\"h2\", {\n    \"id\": \"kafka\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Kafka\"), mdx(\"p\", null, \"Kafka [\", mdx(\"a\", {\n    \"href\": \"producer\",\n    \"title\": \"Producer\",\n    \"parentName\": \"p\"\n  }, \"Producer\"), \"]\"), mdx(\"p\", null, \"Kafka [\", mdx(\"a\", {\n    \"href\": \"consumer\",\n    \"title\": \"Consumer\",\n    \"parentName\": \"p\"\n  }, \"Consumer\"), \"]\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"80160a7b-29c9-59fa-866f-c39ebab1da04","fields":{"slug":"/rust","title":"Rust"}}}]},"fields":{"slug":"/producer","title":"Producer"}}},"pageContext":{"id":"67abd20c-6607-580b-bb55-74eeb8467444"}},"staticQueryHashes":["2098632890","426988268"]}