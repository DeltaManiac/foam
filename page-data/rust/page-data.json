{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/rust","result":{"data":{"file":{"childMdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"rust\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Rust\"), mdx(\"h2\", {\n    \"id\": \"kafka\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Kafka\"), mdx(\"p\", null, \"Kafka [\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"producer\",\n    \"title\": \"Producer\"\n  }), \"Producer\"), \"]\"), mdx(\"p\", null, \"Kafka [\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"consumer\",\n    \"title\": \"Consumer\"\n  }), \"Consumer\"), \"]\"));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"producer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Producer\"), mdx(\"p\", null, \"Kafka has a binary wire protocol.This means that it is possible for applications to read messages from Kafka or write messages to Kafka simply by sending the correct byte sequences to Kafka\\u2019s network port.\"), mdx(\"p\", null, \"Key Structure is \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ProducerRecord\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }), \"\\n      \", mdx(\"a\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/foam/static/d0959d9b8637f0064119e731a7f44131/47218/kafka_producer.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"86.42857142857143%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsSAAALEgHS3X78AAACz0lEQVQ4y42UzU8TQRjGezAx8Ui86Z/gyYOJF+/+ISYeiIncNEQPJBxMPHESEyqpwSAI2lYoIC2FdtttU6EU+WgRCS203d2W7mc/tt3HmcGFllZ008lun3nn977vzLPraDab+PdowWw0wO/8gju8Dg+3gehWBmi1zmMsy4Ku63DgPy+LLJqIxDD48R1ezrjgXAoQ0YJF5yyLxVSrVTjoH3vQq0WyKoqCSqWCUqkEWZahaRpO8nl84+LguTD4cAiLoRhMkgS9gO1ivV5nwFqtxqBUp0mquoFZPg6n34v3oQVMroRYy13AdsEG0r2gQFodnTObJtvDwEYKH4IBjHrd8HE8WqTChmmyhF0V2mKDLJQkiVVJ7zQBhdfrNIGCIJ+Ed2kN5fIpia3DMAxWQBewWCxie3sbqVQKuVyOVXZwcIB0Oo18ocBiJFmDa5GDyxeCeKqctUtGT6C9Z4IgMDitlD5TjVbDgBUV08EEpgIxlGSVafRgOoCX95C2brdqVGsXullH7vgYUwurmJxbxlE2S73E5mjbV56yKEqoVQ2UhROoehV8OgcvMXR4N4u8IKJYlhFI7mOeTyGeOYZA4m3wubHbgaVyBYXDHUQ/j4DjeQy5N9D/1oeByRhWk2mEdnPoHw/iiXMZw+4Eq/xqIDG0YejYXE9AUxXcee7GjYFFXHs8i7nIJj5xu3A8mmba3WdTKEvC34HUb4WiCCl/iL2oB0Ixj3tDPtwe9KNv4CvmoluY4TPoe+rBLaLdfzEDSSj2BtpQWVFx9HMHEd8Es4x7bR1jniDG3CvI7O0RK+1jdHYZ4/NhfAnGyZ6L3cDLp61pOsTSqT1DfiYMXcUbfwLOle+okWc0G/T8YZK3pcM27bDz1kkQffVokKzqbLH/RxbXh2O4+SqGZLZ8Fte6KKID2AtKzU5Nq5EPQ6tRw9ZhAQ9eR/BwJIqspPzxrdXxcfgNf03r4ZuuMzAAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"kafka producer\",\n    \"title\": \"kafka producer\",\n    \"src\": \"/foam/static/d0959d9b8637f0064119e731a7f44131/410f3/kafka_producer.png\",\n    \"srcSet\": [\"/foam/static/d0959d9b8637f0064119e731a7f44131/0d3e1/kafka_producer.png 140w\", \"/foam/static/d0959d9b8637f0064119e731a7f44131/6b1e2/kafka_producer.png 281w\", \"/foam/static/d0959d9b8637f0064119e731a7f44131/410f3/kafka_producer.png 561w\", \"/foam/static/d0959d9b8637f0064119e731a7f44131/99072/kafka_producer.png 842w\", \"/foam/static/d0959d9b8637f0064119e731a7f44131/62a6a/kafka_producer.png 1122w\", \"/foam/static/d0959d9b8637f0064119e731a7f44131/47218/kafka_producer.png 1344w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n  \"), \"\\n    \")), mdx(\"h1\", {\n    \"id\": \"serializer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Serializer\"), mdx(\"p\", null, \"Converts between wire format and code\"), mdx(\"p\", null, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://https://avro.apache.org/docs/current\"\n  }), \"Apache Avro\"), \"\\nDefine a common schema for serialization and deserialization\\nStore in schema Registry\\nStore schema identifier in produced message\\n\", mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"34.285714285714285%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAABVklEQVQoz3WSS0vDQBSF+0/c6sp/5j8QEVFw4UrcuNAiVFuwYqkNAUsWtQUh9UFDHyRtY2oFN22TSTt5z7FJm9qAnsXAXOZ8597LpBhjYCxAqMm3is4zB/VdQF9uQlYUDDQNZ+UWjksSdGIifD8zDSgvj5BFHl89CSw0RxyGVHgEwQLYkkRcZHNIZ7OoCDx6XQVV8Q1bBwI29iuoNhQwz0VXbuMqk8b5TQ5cMY8F7w/gh9rDbZHDPcfjc/AR1YKA4YRvYq/QAKF2VLPoDIWHEjL5Aup1MQnEUuElFDF0sMDHf/L9RbhtWZgS49e79Kdicgw0CAGlFNp8d8PhEK7r4vJJwWm5DWo7K7DjODBNM9HMqsN1oG3bGI1GaHc60NQ+JLmP7UMBm0c11KQuXGsGXTcwHo+j4HV/YuT1pHinoeh8tN27V+xci5iQafQjPM+bj+4nPLF+ANH0CNIkHsWOAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"apache avro\",\n    \"title\": \"apache avro\",\n    \"src\": \"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/410f3/apache_avro.png\",\n    \"srcSet\": [\"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/0d3e1/apache_avro.png 140w\", \"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/6b1e2/apache_avro.png 281w\", \"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/410f3/apache_avro.png 561w\", \"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/99072/apache_avro.png 842w\", \"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/62a6a/apache_avro.png 1122w\", \"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/1843f/apache_avro.png 1186w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"h1\", {\n    \"id\": \"creating-a-producer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Creating a Producer\"), mdx(\"h2\", {\n    \"id\": \"in-rust\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"In [\", mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"rust\",\n    \"title\": \"Rust\"\n  }), \"rust\"), \"]\"), mdx(\"p\", null, \"Crate : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://crates.io/crates/kafka\"\n  }), \"kafka\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-rust\"\n  }), \"/// Producer Code\\nuse std::fmt::Write;\\nuse std::time::Duration;\\nuse kafka::producer::{Producer, Record, RequiredAcks};\\n\\nlet mut producer = Producer::from_hosts(vec!(\\\"localhost:9092\\\".to_owned()))\\n.with_ack_timeout(Duration::from_secs(1))\\n.with_required_acks(RequiredAcks::One)\\n.create()\\n.unwrap();\\n\\nlet mut buf = String::with*capacity(2);\\nfor i in 0..10 {\\nlet * = write!(&mut buf, \\\"{}\\\", i); // some computation of the message data to be sent\\nproducer.send(&Record::from_value(\\\"my-topic\\\", buf.as_bytes())).unwrap();\\nbuf.clear();\\n}\\n\")), mdx(\"p\", null, \"Crate : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://crates.io/crates/rdkafka\"\n  }), \"rdkafka\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-Rust\"\n  }), \" sync fn produce(brokers: &str, topic_name: &str) {\\n    let producer: &FutureProducer = &ClientConfig::new()\\n        .set(\\\"bootstrap.servers\\\", brokers)\\n        .set(\\\"message.timeout.ms\\\", \\\"5000\\\")\\n        .create()\\n        .expect(\\\"Producer creation error\\\");\\n\\n    // This loop is non blocking: all messages will be sent one after the other, without waiting\\n    // for the results.\\n    let futures = (0..5)\\n        .map(|i| async move {\\n            // The send operation on the topic returns a future, which will be\\n            // completed once the result or failure from Kafka is received.\\n            let delivery_status = producer\\n                .send(\\n                    FutureRecord::to(topic_name)\\n                        .payload(&format!(\\\"Message {}\\\", i))\\n                        .key(&format!(\\\"Key {}\\\", i))\\n                        .headers(OwnedHeaders::new().add(\\\"header_key\\\", \\\"header_value\\\")),\\n                    Duration::from_secs(0),\\n                )\\n                .await;\\n\\n            // This will be executed when the result is received.\\n            info!(\\\"Delivery status for message {} received\\\", i);\\n            delivery_status\\n        })\\n        .collect::<Vec<_>>();\\n\\n    // This loop will wait until all delivery statuses have been received.\\n    for future in futures {\\n        info!(\\\"Future completed. Result: {:?}\\\", future.await);\\n    }\\n}\\n\\n\")), mdx(\"p\", null, \"Schema Registry for confluent : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/gklijs/schema_registry_converter\"\n  }), \"https://github.com/gklijs/schema_registry_converter\")), mdx(\"p\", null, \"Confluent Write up : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.confluent.io/blog/getting-started-with-rust-and-kafka/\"\n  }), \"https://www.confluent.io/blog/getting-started-with-rust-and-kafka/\")), mdx(\"hr\", null), mdx(\"h2\", {\n    \"id\": \"in-golang\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"In [\", mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"golang\",\n    \"title\": \"Golang\"\n  }), \"golang\"), \"]\"), mdx(\"p\", null, \"Package : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/confluentinc/confluent-kafka-go\"\n  }), \"Confluent Inc\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-golang\"\n  }), \"func main() {\\n\\n    p, err := kafka.NewProducer(&kafka.ConfigMap{\\\"bootstrap.servers\\\": \\\"localhost\\\"})\\n    if err != nil {\\n        panic(err)\\n    }\\n\\n    defer p.Close()\\n\\n    // Delivery report handler for produced messages\\n    go func() {\\n        for e := range p.Events() {\\n            switch ev := e.(type) {\\n            case *kafka.Message:\\n                if ev.TopicPartition.Error != nil {\\n                    fmt.Printf(\\\"Delivery failed: %v\\\\n\\\", ev.TopicPartition)\\n                } else {\\n                    fmt.Printf(\\\"Delivered message to %v\\\\n\\\", ev.TopicPartition)\\n                }\\n            }\\n        }\\n    }()\\n\\n    // Produce messages to topic (asynchronously)\\n    topic := \\\"myTopic\\\"\\n    for _, word := range []string{\\\"Welcome\\\", \\\"to\\\", \\\"the\\\", \\\"Confluent\\\", \\\"Kafka\\\", \\\"Golang\\\", \\\"client\\\"} {\\n        p.Produce(&kafka.Message{\\n            TopicPartition: kafka.TopicPartition{Topic: &topic, Partition: kafka.PartitionAny},\\n            Value:          []byte(word),\\n        }, nil)\\n    }\\n\\n    // Wait for message deliveries before shutting down\\n    p.Flush(15 * 1000)\\n}\\n\")), mdx(\"p\", null, \"Package : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/segmentio/kafka-go\"\n  }), \"SegmentIO\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-golang\"\n  }), \"func producer() {\\n\\n    topic := \\\"my-topic\\\"\\n    partition := 0\\n\\n    conn, _ := kafka.DialLeader(context.Background(), \\\"tcp\\\", \\\"localhost:9092\\\", topic, partition)\\n\\n    conn.SetWriteDeadline(time.Now().Add(10*time.Second))\\n    conn.WriteMessages(\\n    kafka.Message{Value: []byte(\\\"one!\\\")},\\n    kafka.Message{Value: []byte(\\\"two!\\\")},\\n    kafka.Message{Value: []byte(\\\"three!\\\")},\\n    )\\n\\n    conn.Close()\\n}\\n\")), mdx(\"p\", null, \"Package : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/Shopify/sarama\"\n  }), \"Sarama\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-golang\"\n  }), \"//Sync Producer\\nfunc newDataCollector(brokerList []string) sarama.SyncProducer {\\n\\n    // For the data collector, we are looking for strong consistency semantics.\\n    // Because we don't change the flush settings, sarama will try to produce messages\\n    // as fast as possible to keep latency low.\\n    config := sarama.NewConfig()\\n    config.Producer.RequiredAcks = sarama.WaitForAll // Wait for all in-sync replicas to ack the message\\n    config.Producer.Retry.Max = 10                   // Retry up to 10 times to produce the message\\n    config.Producer.Return.Successes = true\\n    tlsConfig := createTlsConfiguration()\\n    if tlsConfig != nil {\\n        config.Net.TLS.Config = tlsConfig\\n        config.Net.TLS.Enable = true\\n    }\\n\\n    // On the broker side, you may want to change the following settings to get\\n    // stronger consistency guarantees:\\n    // - For your broker, set `unclean.leader.election.enable` to false\\n    // - For the topic, you could increase `min.insync.replicas`.\\n\\n    producer, err := sarama.NewSyncProducer(brokerList, config)\\n    if err != nil {\\n        log.Fatalln(\\\"Failed to start Sarama producer:\\\", err)\\n    }\\n\\n    return producer\\n}\\n\\n// Async Producer\\nfunc newAccessLogProducer(brokerList []string) sarama.AsyncProducer {\\n\\n    // For the access log, we are looking for AP semantics, with high throughput.\\n    // By creating batches of compressed messages, we reduce network I/O at a cost of more latency.\\n    config := sarama.NewConfig()\\n    tlsConfig := createTlsConfiguration()\\n    if tlsConfig != nil {\\n        config.Net.TLS.Enable = true\\n        config.Net.TLS.Config = tlsConfig\\n    }\\n    config.Producer.RequiredAcks = sarama.WaitForLocal       // Only wait for the leader to ack\\n    config.Producer.Compression = sarama.CompressionSnappy   // Compress messages\\n    config.Producer.Flush.Frequency = 500 * time.Millisecond // Flush batches every 500ms\\n\\n    producer, err := sarama.NewAsyncProducer(brokerList, config)\\n    if err != nil {\\n        log.Fatalln(\\\"Failed to start Sarama producer:\\\", err)\\n    }\\n\\n    // We will just log to STDOUT if we're not able to produce messages.\\n    // Note: messages will only be returned here after all retry attempts are exhausted.\\n    go func() {\\n        for err := range producer.Errors() {\\n            log.Println(\\\"Failed to write access log entry:\\\", err)\\n        }\\n    }()\\n\\n    return producer\\n}\\n\\ngo func sendMessage(){\\n        // Synch\\n        partition, offset, err := s.DataCollector.SendMessage(&sarama.ProducerMessage{\\n            Topic: \\\"important\\\",\\n            Value: sarama.StringEncoder(r.URL.RawQuery),\\n        })\\n        // Async\\n        s.AccessLogProducer.Input() <- &sarama.ProducerMessage{\\n            Topic: \\\"access_log\\\",\\n            Key:   sarama.StringEncoder(r.RemoteAddr),\\n            Value: entry,\\n        }\\n}\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"67abd20c-6607-580b-bb55-74eeb8467444","fields":{"slug":"/producer","title":"Producer"}}},{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"consumer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Consumer\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Subscribes to topics and receives message\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Consumer Group -> method of scaling consumption\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Membership triggered by a \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"JoinGroup\"), \" call\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"First member is the de-facto group leader\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"leader assigns partitions to consumers in the consumer group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Membership is maintained by sending \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"heartbeats\"), \" at intervals regularly to the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"group coordinator\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Sent during \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"poll\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"commit\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"missing heartbeats for a period will trigger rebalance as the consumer is thought to be dead\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Rebalance\"), \" moving partition ownership from one consumer to another\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"high scalability and availability\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"creates a short unavailability window\")))), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }), \"\\n      \", mdx(\"a\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/foam/static/904963a471d97607ad62651a9f807b77/3fca6/kafka_consumer.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"57.85714285714286%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAABsklEQVQoz5WS+2/SYBSG9/ebmMVFnUYTrmMUWm6lhcKgwMAJKmxdhzELwhYHglzGuM0f4LESSNQsWt/kzTn5zjlPTk6+HTZarVbr2Or00c1r0tVLsudXGI0bJrM79I/v0cwy2kWFrFlhPp//NrfVzjZZbgq1Rgfx5BMhvYxYNImVzvnSa3NQEJEzbmTdiyPjZzi+tQc0Wl38Sga/IOA5DCLEdeqfL3GFX6F4H6EePsatuBlNJ/aAZ82vSOkSSS2FFE0QlbO0um0EzUsh+oxc7DkuxcVoYhNoNLvWcBExIuMLKUTFBI3rJgcJD6q4hxp6itvKbQNPLaCUKqIoccRYgqAvRt2oWUAneWkXPfQEZ9xhH2g22/jTbxG1Aj7rfsl4lqvTKuFjGTUbRNVFArkI43/dcFv4fn9PfzCgPxytPe19o2cYhJNhPMca3nwCJX/EbDb7O/Ch4lY39QskYZ9Aymmdw4VwJDEaj+1t+DNuvVwu12/dXpdkYJ936ksqygs8qo1v86fWwE1z53aAkPISCewSlfZ4LTsY3o3/D/hr83Q+o2R+IFd9Y/mEQq3MYrF4EPgDn+9wMMMANmUAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"kafka consumer\",\n    \"title\": \"kafka consumer\",\n    \"src\": \"/foam/static/904963a471d97607ad62651a9f807b77/410f3/kafka_consumer.png\",\n    \"srcSet\": [\"/foam/static/904963a471d97607ad62651a9f807b77/0d3e1/kafka_consumer.png 140w\", \"/foam/static/904963a471d97607ad62651a9f807b77/6b1e2/kafka_consumer.png 281w\", \"/foam/static/904963a471d97607ad62651a9f807b77/410f3/kafka_consumer.png 561w\", \"/foam/static/904963a471d97607ad62651a9f807b77/99072/kafka_consumer.png 842w\", \"/foam/static/904963a471d97607ad62651a9f807b77/3fca6/kafka_consumer.png 1112w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n  \"), \"\\n    \")), mdx(\"h1\", {\n    \"id\": \"creating-a-consumer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Creating a Consumer\"), mdx(\"h2\", {\n    \"id\": \"in-rust\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"In [\", mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"rust\",\n    \"title\": \"Rust\"\n  }), \"rust\"), \"]\"), mdx(\"p\", null, \"Crate : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://crates.io/crates/kafka\"\n  }), \"kafka\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-Rust\"\n  }), \"use kafka::consumer::{Consumer, FetchOffset, GroupOffsetStorage};\\nlet mut consumer =\\n   Consumer::from_hosts(vec!(\\\"localhost:9092\\\".to_owned()))\\n      .with_topic_partitions(\\\"my-topic\\\".to_owned(), &[0, 1])\\n      .with_fallback_offset(FetchOffset::Earliest)\\n      .with_group(\\\"my-group\\\".to_owned())\\n      .with_offset_storage(GroupOffsetStorage::Kafka)\\n      .create()\\n      .unwrap();\\nloop {\\n  for ms in consumer.poll().unwrap().iter() {\\n    for m in ms.messages() {\\n      println!(\\\"{:?}\\\", m);\\n    }\\n    consumer.consume_messageset(ms);\\n  }\\n  consumer.commit_consumed().unwrap();\\n}\\n\")), mdx(\"p\", null, \"Crate : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://crates.io/crates/rdkafka\"\n  }), \"rdkafka\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-Rust\"\n  }), \"async fn consume(brokers: &str, group_id: &str, topics: &[&str]) {\\n    let context = CustomContext;\\n\\n    let consumer: LoggingConsumer = ClientConfig::new()\\n        .set(\\\"group.id\\\", group_id)\\n        .set(\\\"bootstrap.servers\\\", brokers)\\n        .set(\\\"enable.partition.eof\\\", \\\"false\\\")\\n        .set(\\\"session.timeout.ms\\\", \\\"6000\\\")\\n        .set(\\\"enable.auto.commit\\\", \\\"true\\\")\\n        //.set(\\\"statistics.interval.ms\\\", \\\"30000\\\")\\n        //.set(\\\"auto.offset.reset\\\", \\\"smallest\\\")\\n        .set_log_level(RDKafkaLogLevel::Debug)\\n        .create_with_context(context)\\n        .expect(\\\"Consumer creation failed\\\");\\n\\n    consumer\\n        .subscribe(&topics.to_vec())\\n        .expect(\\\"Can't subscribe to specified topics\\\");\\n\\n    // consumer.start() returns a stream. The stream can be used ot chain together expensive steps,\\n    // such as complex computations on a thread pool or asynchronous IO.\\n    let mut message_stream = consumer.start();\\n\\n    while let Some(message) = message_stream.next().await {\\n        match message {\\n            Err(e) => warn!(\\\"Kafka error: {}\\\", e),\\n            Ok(m) => {\\n                let payload = match m.payload_view::<str>() {\\n                    None => \\\"\\\",\\n                    Some(Ok(s)) => s,\\n                    Some(Err(e)) => {\\n                        warn!(\\\"Error while deserializing message payload: {:?}\\\", e);\\n                        \\\"\\\"\\n                    }\\n                };\\n                info!(\\\"key: '{:?}', payload: '{}', topic: {}, partition: {}, offset: {}, timestamp: {:?}\\\",\\n                      m.key(), payload, m.topic(), m.partition(), m.offset(), m.timestamp());\\n                if let Some(headers) = m.headers() {\\n                    for i in 0..headers.count() {\\n                        let header = headers.get(i).unwrap();\\n                        info!(\\\"  Header {:#?}: {:?}\\\", header.0, header.1);\\n                    }\\n                }\\n                consumer.commit_message(&m, CommitMode::Async).unwrap();\\n            }\\n        };\\n    }\\n}\\n\")), mdx(\"hr\", null), mdx(\"h2\", {\n    \"id\": \"in-golang\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"In [\", mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"golang\",\n    \"title\": \"Golang\"\n  }), \"golang\"), \"]\"), mdx(\"p\", null, \"Package : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/confluentinc/confluent-kafka-go\"\n  }), \"Confluent Inc\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-golang\"\n  }), \"func main() {\\n\\n    c, err := kafka.NewConsumer(&kafka.ConfigMap{\\n        \\\"bootstrap.servers\\\": \\\"localhost\\\",\\n        \\\"group.id\\\":          \\\"myGroup\\\",\\n        \\\"auto.offset.reset\\\": \\\"earliest\\\",\\n    })\\n\\n    if err != nil {\\n        panic(err)\\n    }\\n\\n    c.SubscribeTopics([]string{\\\"myTopic\\\", \\\"^aRegex.*[Tt]opic\\\"}, nil)\\n\\n    for {\\n        msg, err := c.ReadMessage(-1)\\n        if err == nil {\\n            fmt.Printf(\\\"Message on %s: %s\\\\n\\\", msg.TopicPartition, string(msg.Value))\\n        } else {\\n            // The client will automatically try to recover from all errors.\\n            fmt.Printf(\\\"Consumer error: %v (%v)\\\\n\\\", err, msg)\\n        }\\n    }\\n\\n    c.Close()\\n}\\n\")), mdx(\"h2\", {\n    \"id\": \"package--segmentio\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Package : \", mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"https://github.com/segmentio/kafka-go\"\n  }), \"SegmentIO\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-golang\"\n  }), \"func consumer(){}\\nr := kafka.NewReader(kafka.ReaderConfig{\\n    Brokers:   []string{\\\"localhost:9092\\\"},\\n    Topic:     \\\"topic-A\\\",\\n    Partition: 0,\\n    MinBytes:  10e3, // 10KB\\n    MaxBytes:  10e6, // 10MB\\n})\\nr.SetOffset(42)\\n\\nfor {\\n    m, err := r.ReadMessage(context.Background())\\n    if err != nil {\\n        break\\n    }\\n    fmt.Printf(\\\"message at offset %d: %s = %s\\\\n\\\", m.Offset, string(m.Key), string(m.Value))\\n}\\n\\nr.Close()\\n}\\n\")), mdx(\"p\", null, \"Package : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/Shopify/sarama\"\n  }), \"Sarama\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-golang\"\n  }), \"// ConsumeClaim must start a consumer loop of ConsumerGroupClaim's Messages().\\nfunc (consumer *Consumer) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {\\n\\n    // NOTE:\\n    // Do not move the code below to a goroutine.\\n    // The `ConsumeClaim` itself is called within a goroutine, see:\\n    // https://github.com/Shopify/sarama/blob/master/consumer_group.go#L27-L29\\n    for message := range claim.Messages() {\\n        log.Printf(\\\"Message claimed: value = %s, timestamp = %v, topic = %s\\\", string(message.Value), message.Timestamp, message.Topic)\\n        session.MarkMessage(message, \\\"\\\")\\n    }\\n\\n    return nil\\n}\\n\\ngo func() comsumer{\\n        defer wg.Done()\\n        for {\\n            // `Consume` should be called inside an infinite loop, when a\\n            // server-side rebalance happens, the consumer session will need to be\\n            // recreated to get the new claims\\n            if err := client.Consume(ctx, strings.Split(topics, \\\",\\\"), &consumer); err != nil {\\n                log.Panicf(\\\"Error from consumer: %v\\\", err)\\n            }\\n            // check if context was cancelled, signaling that the consumer should stop\\n            if ctx.Err() != nil {\\n                return\\n            }\\n            consumer.ready = make(chan bool)\\n        }\\n    }()\\n\\n\")), mdx(\"h1\", {\n    \"id\": \"commits\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Commits\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Consumers use kafka to track their position in each partition\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"commit\"), \" act of updating current position in kafka\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"message \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"__consumer_offsets\"), \" topic with the offset for each partition\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"when rebalance each consumer receives a new partition and obtains the latest committed offset from where to start reading\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Commit Strategy\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Automatic\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Done by consumer every 5 seconds configurable\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Commits largest offset from \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"poll\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"call to \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"poll\"), \" will always commit the last offset\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"results in double processing if \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"rebalance\"), \" occurs in between a 5 sec window\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Commit Current Offset\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Gives control to the developer\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"commitSync\"), \" triggers commit of the last offset returned by \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"poll\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"must be called after processing all messages\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Synchronous call blocks the application\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Auto retry till success of non retry-able failure\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Asynchronous Commit\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Fire and forget till we get a callback\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Does not auto retry as a later commit request might have latest Offset\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Async + Sync Commit\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"CommitAsync\"), \" always\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Trigger a CommitSync just before exit\")))))));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"a9f33b82-4aa7-599b-a242-54db28ac76f1","fields":{"slug":"/consumer","title":"Consumer"}}}],"inboundReferences":[{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"foam-bubbles\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Foam Bubbles\"), mdx(\"p\", null, \"[\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"inbox\",\n    \"title\": \"Inbox\"\n  }), \"inbox\"), \"]\"), mdx(\"p\", null, \"[\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"todo\",\n    \"title\": \"Todo / Reading List\"\n  }), \"todo\"), \"]\"), mdx(\"p\", null, \"[\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"dwarf\",\n    \"title\": \"Dwarf Debugging Format\"\n  }), \"dwarf\"), \"]\"), mdx(\"p\", null, \"[\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"kafka\",\n    \"title\": \"Apache Kafka\"\n  }), \"kafka\"), \"]\"), mdx(\"p\", null, \"[\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"elf\",\n    \"title\": \"elf\"\n  }), \"elf\"), \"]\"), mdx(\"p\", null, \"[\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"rust\",\n    \"title\": \"Rust\"\n  }), \"rust\"), \"]\"), mdx(\"p\", null, \"[\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"golang\",\n    \"title\": \"Golang\"\n  }), \"golang\"), \"]\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"0b774b8d-a51d-55d2-8d2d-8f7d194fe0d5","fields":{"slug":"/readme","title":"Foam Bubbles"}}},{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"producer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Producer\"), mdx(\"p\", null, \"Kafka has a binary wire protocol.This means that it is possible for applications to read messages from Kafka or write messages to Kafka simply by sending the correct byte sequences to Kafka\\u2019s network port.\"), mdx(\"p\", null, \"Key Structure is \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ProducerRecord\")), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }), \"\\n      \", mdx(\"a\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/foam/static/d0959d9b8637f0064119e731a7f44131/47218/kafka_producer.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"86.42857142857143%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsSAAALEgHS3X78AAACz0lEQVQ4y42UzU8TQRjGezAx8Ui86Z/gyYOJF+/+ISYeiIncNEQPJBxMPHESEyqpwSAI2lYoIC2FdtttU6EU+WgRCS203d2W7mc/tt3HmcGFllZ008lun3nn977vzLPraDab+PdowWw0wO/8gju8Dg+3gehWBmi1zmMsy4Ku63DgPy+LLJqIxDD48R1ezrjgXAoQ0YJF5yyLxVSrVTjoH3vQq0WyKoqCSqWCUqkEWZahaRpO8nl84+LguTD4cAiLoRhMkgS9gO1ivV5nwFqtxqBUp0mquoFZPg6n34v3oQVMroRYy13AdsEG0r2gQFodnTObJtvDwEYKH4IBjHrd8HE8WqTChmmyhF0V2mKDLJQkiVVJ7zQBhdfrNIGCIJ+Ed2kN5fIpia3DMAxWQBewWCxie3sbqVQKuVyOVXZwcIB0Oo18ocBiJFmDa5GDyxeCeKqctUtGT6C9Z4IgMDitlD5TjVbDgBUV08EEpgIxlGSVafRgOoCX95C2brdqVGsXullH7vgYUwurmJxbxlE2S73E5mjbV56yKEqoVQ2UhROoehV8OgcvMXR4N4u8IKJYlhFI7mOeTyGeOYZA4m3wubHbgaVyBYXDHUQ/j4DjeQy5N9D/1oeByRhWk2mEdnPoHw/iiXMZw+4Eq/xqIDG0YejYXE9AUxXcee7GjYFFXHs8i7nIJj5xu3A8mmba3WdTKEvC34HUb4WiCCl/iL2oB0Ixj3tDPtwe9KNv4CvmoluY4TPoe+rBLaLdfzEDSSj2BtpQWVFx9HMHEd8Es4x7bR1jniDG3CvI7O0RK+1jdHYZ4/NhfAnGyZ6L3cDLp61pOsTSqT1DfiYMXcUbfwLOle+okWc0G/T8YZK3pcM27bDz1kkQffVokKzqbLH/RxbXh2O4+SqGZLZ8Fte6KKID2AtKzU5Nq5EPQ6tRw9ZhAQ9eR/BwJIqspPzxrdXxcfgNf03r4ZuuMzAAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"kafka producer\",\n    \"title\": \"kafka producer\",\n    \"src\": \"/foam/static/d0959d9b8637f0064119e731a7f44131/410f3/kafka_producer.png\",\n    \"srcSet\": [\"/foam/static/d0959d9b8637f0064119e731a7f44131/0d3e1/kafka_producer.png 140w\", \"/foam/static/d0959d9b8637f0064119e731a7f44131/6b1e2/kafka_producer.png 281w\", \"/foam/static/d0959d9b8637f0064119e731a7f44131/410f3/kafka_producer.png 561w\", \"/foam/static/d0959d9b8637f0064119e731a7f44131/99072/kafka_producer.png 842w\", \"/foam/static/d0959d9b8637f0064119e731a7f44131/62a6a/kafka_producer.png 1122w\", \"/foam/static/d0959d9b8637f0064119e731a7f44131/47218/kafka_producer.png 1344w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n  \"), \"\\n    \")), mdx(\"h1\", {\n    \"id\": \"serializer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Serializer\"), mdx(\"p\", null, \"Converts between wire format and code\"), mdx(\"p\", null, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://https://avro.apache.org/docs/current\"\n  }), \"Apache Avro\"), \"\\nDefine a common schema for serialization and deserialization\\nStore in schema Registry\\nStore schema identifier in produced message\\n\", mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"34.285714285714285%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAABVklEQVQoz3WSS0vDQBSF+0/c6sp/5j8QEVFw4UrcuNAiVFuwYqkNAUsWtQUh9UFDHyRtY2oFN22TSTt5z7FJm9qAnsXAXOZ8597LpBhjYCxAqMm3is4zB/VdQF9uQlYUDDQNZ+UWjksSdGIifD8zDSgvj5BFHl89CSw0RxyGVHgEwQLYkkRcZHNIZ7OoCDx6XQVV8Q1bBwI29iuoNhQwz0VXbuMqk8b5TQ5cMY8F7w/gh9rDbZHDPcfjc/AR1YKA4YRvYq/QAKF2VLPoDIWHEjL5Aup1MQnEUuElFDF0sMDHf/L9RbhtWZgS49e79Kdicgw0CAGlFNp8d8PhEK7r4vJJwWm5DWo7K7DjODBNM9HMqsN1oG3bGI1GaHc60NQ+JLmP7UMBm0c11KQuXGsGXTcwHo+j4HV/YuT1pHinoeh8tN27V+xci5iQafQjPM+bj+4nPLF+ANH0CNIkHsWOAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"apache avro\",\n    \"title\": \"apache avro\",\n    \"src\": \"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/410f3/apache_avro.png\",\n    \"srcSet\": [\"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/0d3e1/apache_avro.png 140w\", \"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/6b1e2/apache_avro.png 281w\", \"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/410f3/apache_avro.png 561w\", \"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/99072/apache_avro.png 842w\", \"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/62a6a/apache_avro.png 1122w\", \"/foam/static/8e49d63081d54fef00a8c14d7ba25b4b/1843f/apache_avro.png 1186w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"h1\", {\n    \"id\": \"creating-a-producer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Creating a Producer\"), mdx(\"h2\", {\n    \"id\": \"in-rust\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"In [\", mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"rust\",\n    \"title\": \"Rust\"\n  }), \"rust\"), \"]\"), mdx(\"p\", null, \"Crate : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://crates.io/crates/kafka\"\n  }), \"kafka\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-rust\"\n  }), \"/// Producer Code\\nuse std::fmt::Write;\\nuse std::time::Duration;\\nuse kafka::producer::{Producer, Record, RequiredAcks};\\n\\nlet mut producer = Producer::from_hosts(vec!(\\\"localhost:9092\\\".to_owned()))\\n.with_ack_timeout(Duration::from_secs(1))\\n.with_required_acks(RequiredAcks::One)\\n.create()\\n.unwrap();\\n\\nlet mut buf = String::with*capacity(2);\\nfor i in 0..10 {\\nlet * = write!(&mut buf, \\\"{}\\\", i); // some computation of the message data to be sent\\nproducer.send(&Record::from_value(\\\"my-topic\\\", buf.as_bytes())).unwrap();\\nbuf.clear();\\n}\\n\")), mdx(\"p\", null, \"Crate : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://crates.io/crates/rdkafka\"\n  }), \"rdkafka\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-Rust\"\n  }), \" sync fn produce(brokers: &str, topic_name: &str) {\\n    let producer: &FutureProducer = &ClientConfig::new()\\n        .set(\\\"bootstrap.servers\\\", brokers)\\n        .set(\\\"message.timeout.ms\\\", \\\"5000\\\")\\n        .create()\\n        .expect(\\\"Producer creation error\\\");\\n\\n    // This loop is non blocking: all messages will be sent one after the other, without waiting\\n    // for the results.\\n    let futures = (0..5)\\n        .map(|i| async move {\\n            // The send operation on the topic returns a future, which will be\\n            // completed once the result or failure from Kafka is received.\\n            let delivery_status = producer\\n                .send(\\n                    FutureRecord::to(topic_name)\\n                        .payload(&format!(\\\"Message {}\\\", i))\\n                        .key(&format!(\\\"Key {}\\\", i))\\n                        .headers(OwnedHeaders::new().add(\\\"header_key\\\", \\\"header_value\\\")),\\n                    Duration::from_secs(0),\\n                )\\n                .await;\\n\\n            // This will be executed when the result is received.\\n            info!(\\\"Delivery status for message {} received\\\", i);\\n            delivery_status\\n        })\\n        .collect::<Vec<_>>();\\n\\n    // This loop will wait until all delivery statuses have been received.\\n    for future in futures {\\n        info!(\\\"Future completed. Result: {:?}\\\", future.await);\\n    }\\n}\\n\\n\")), mdx(\"p\", null, \"Schema Registry for confluent : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/gklijs/schema_registry_converter\"\n  }), \"https://github.com/gklijs/schema_registry_converter\")), mdx(\"p\", null, \"Confluent Write up : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.confluent.io/blog/getting-started-with-rust-and-kafka/\"\n  }), \"https://www.confluent.io/blog/getting-started-with-rust-and-kafka/\")), mdx(\"hr\", null), mdx(\"h2\", {\n    \"id\": \"in-golang\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"In [\", mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"golang\",\n    \"title\": \"Golang\"\n  }), \"golang\"), \"]\"), mdx(\"p\", null, \"Package : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/confluentinc/confluent-kafka-go\"\n  }), \"Confluent Inc\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-golang\"\n  }), \"func main() {\\n\\n    p, err := kafka.NewProducer(&kafka.ConfigMap{\\\"bootstrap.servers\\\": \\\"localhost\\\"})\\n    if err != nil {\\n        panic(err)\\n    }\\n\\n    defer p.Close()\\n\\n    // Delivery report handler for produced messages\\n    go func() {\\n        for e := range p.Events() {\\n            switch ev := e.(type) {\\n            case *kafka.Message:\\n                if ev.TopicPartition.Error != nil {\\n                    fmt.Printf(\\\"Delivery failed: %v\\\\n\\\", ev.TopicPartition)\\n                } else {\\n                    fmt.Printf(\\\"Delivered message to %v\\\\n\\\", ev.TopicPartition)\\n                }\\n            }\\n        }\\n    }()\\n\\n    // Produce messages to topic (asynchronously)\\n    topic := \\\"myTopic\\\"\\n    for _, word := range []string{\\\"Welcome\\\", \\\"to\\\", \\\"the\\\", \\\"Confluent\\\", \\\"Kafka\\\", \\\"Golang\\\", \\\"client\\\"} {\\n        p.Produce(&kafka.Message{\\n            TopicPartition: kafka.TopicPartition{Topic: &topic, Partition: kafka.PartitionAny},\\n            Value:          []byte(word),\\n        }, nil)\\n    }\\n\\n    // Wait for message deliveries before shutting down\\n    p.Flush(15 * 1000)\\n}\\n\")), mdx(\"p\", null, \"Package : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/segmentio/kafka-go\"\n  }), \"SegmentIO\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-golang\"\n  }), \"func producer() {\\n\\n    topic := \\\"my-topic\\\"\\n    partition := 0\\n\\n    conn, _ := kafka.DialLeader(context.Background(), \\\"tcp\\\", \\\"localhost:9092\\\", topic, partition)\\n\\n    conn.SetWriteDeadline(time.Now().Add(10*time.Second))\\n    conn.WriteMessages(\\n    kafka.Message{Value: []byte(\\\"one!\\\")},\\n    kafka.Message{Value: []byte(\\\"two!\\\")},\\n    kafka.Message{Value: []byte(\\\"three!\\\")},\\n    )\\n\\n    conn.Close()\\n}\\n\")), mdx(\"p\", null, \"Package : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/Shopify/sarama\"\n  }), \"Sarama\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-golang\"\n  }), \"//Sync Producer\\nfunc newDataCollector(brokerList []string) sarama.SyncProducer {\\n\\n    // For the data collector, we are looking for strong consistency semantics.\\n    // Because we don't change the flush settings, sarama will try to produce messages\\n    // as fast as possible to keep latency low.\\n    config := sarama.NewConfig()\\n    config.Producer.RequiredAcks = sarama.WaitForAll // Wait for all in-sync replicas to ack the message\\n    config.Producer.Retry.Max = 10                   // Retry up to 10 times to produce the message\\n    config.Producer.Return.Successes = true\\n    tlsConfig := createTlsConfiguration()\\n    if tlsConfig != nil {\\n        config.Net.TLS.Config = tlsConfig\\n        config.Net.TLS.Enable = true\\n    }\\n\\n    // On the broker side, you may want to change the following settings to get\\n    // stronger consistency guarantees:\\n    // - For your broker, set `unclean.leader.election.enable` to false\\n    // - For the topic, you could increase `min.insync.replicas`.\\n\\n    producer, err := sarama.NewSyncProducer(brokerList, config)\\n    if err != nil {\\n        log.Fatalln(\\\"Failed to start Sarama producer:\\\", err)\\n    }\\n\\n    return producer\\n}\\n\\n// Async Producer\\nfunc newAccessLogProducer(brokerList []string) sarama.AsyncProducer {\\n\\n    // For the access log, we are looking for AP semantics, with high throughput.\\n    // By creating batches of compressed messages, we reduce network I/O at a cost of more latency.\\n    config := sarama.NewConfig()\\n    tlsConfig := createTlsConfiguration()\\n    if tlsConfig != nil {\\n        config.Net.TLS.Enable = true\\n        config.Net.TLS.Config = tlsConfig\\n    }\\n    config.Producer.RequiredAcks = sarama.WaitForLocal       // Only wait for the leader to ack\\n    config.Producer.Compression = sarama.CompressionSnappy   // Compress messages\\n    config.Producer.Flush.Frequency = 500 * time.Millisecond // Flush batches every 500ms\\n\\n    producer, err := sarama.NewAsyncProducer(brokerList, config)\\n    if err != nil {\\n        log.Fatalln(\\\"Failed to start Sarama producer:\\\", err)\\n    }\\n\\n    // We will just log to STDOUT if we're not able to produce messages.\\n    // Note: messages will only be returned here after all retry attempts are exhausted.\\n    go func() {\\n        for err := range producer.Errors() {\\n            log.Println(\\\"Failed to write access log entry:\\\", err)\\n        }\\n    }()\\n\\n    return producer\\n}\\n\\ngo func sendMessage(){\\n        // Synch\\n        partition, offset, err := s.DataCollector.SendMessage(&sarama.ProducerMessage{\\n            Topic: \\\"important\\\",\\n            Value: sarama.StringEncoder(r.URL.RawQuery),\\n        })\\n        // Async\\n        s.AccessLogProducer.Input() <- &sarama.ProducerMessage{\\n            Topic: \\\"access_log\\\",\\n            Key:   sarama.StringEncoder(r.RemoteAddr),\\n            Value: entry,\\n        }\\n}\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"67abd20c-6607-580b-bb55-74eeb8467444","fields":{"slug":"/producer","title":"Producer"}}},{"__typename":"Mdx","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"consumer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Consumer\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Subscribes to topics and receives message\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Consumer Group -> method of scaling consumption\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Membership triggered by a \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"JoinGroup\"), \" call\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"First member is the de-facto group leader\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"leader assigns partitions to consumers in the consumer group\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Membership is maintained by sending \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"heartbeats\"), \" at intervals regularly to the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"group coordinator\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Sent during \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"poll\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"commit\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"missing heartbeats for a period will trigger rebalance as the consumer is thought to be dead\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Rebalance\"), \" moving partition ownership from one consumer to another\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"high scalability and availability\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"creates a short unavailability window\")))), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }), \"\\n      \", mdx(\"a\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/foam/static/904963a471d97607ad62651a9f807b77/3fca6/kafka_consumer.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"57.85714285714286%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAABsklEQVQoz5WS+2/SYBSG9/ebmMVFnUYTrmMUWm6lhcKgwMAJKmxdhzELwhYHglzGuM0f4LESSNQsWt/kzTn5zjlPTk6+HTZarVbr2Or00c1r0tVLsudXGI0bJrM79I/v0cwy2kWFrFlhPp//NrfVzjZZbgq1Rgfx5BMhvYxYNImVzvnSa3NQEJEzbmTdiyPjZzi+tQc0Wl38Sga/IOA5DCLEdeqfL3GFX6F4H6EePsatuBlNJ/aAZ82vSOkSSS2FFE0QlbO0um0EzUsh+oxc7DkuxcVoYhNoNLvWcBExIuMLKUTFBI3rJgcJD6q4hxp6itvKbQNPLaCUKqIoccRYgqAvRt2oWUAneWkXPfQEZ9xhH2g22/jTbxG1Aj7rfsl4lqvTKuFjGTUbRNVFArkI43/dcFv4fn9PfzCgPxytPe19o2cYhJNhPMca3nwCJX/EbDb7O/Ch4lY39QskYZ9Aymmdw4VwJDEaj+1t+DNuvVwu12/dXpdkYJ936ksqygs8qo1v86fWwE1z53aAkPISCewSlfZ4LTsY3o3/D/hr83Q+o2R+IFd9Y/mEQq3MYrF4EPgDn+9wMMMANmUAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"kafka consumer\",\n    \"title\": \"kafka consumer\",\n    \"src\": \"/foam/static/904963a471d97607ad62651a9f807b77/410f3/kafka_consumer.png\",\n    \"srcSet\": [\"/foam/static/904963a471d97607ad62651a9f807b77/0d3e1/kafka_consumer.png 140w\", \"/foam/static/904963a471d97607ad62651a9f807b77/6b1e2/kafka_consumer.png 281w\", \"/foam/static/904963a471d97607ad62651a9f807b77/410f3/kafka_consumer.png 561w\", \"/foam/static/904963a471d97607ad62651a9f807b77/99072/kafka_consumer.png 842w\", \"/foam/static/904963a471d97607ad62651a9f807b77/3fca6/kafka_consumer.png 1112w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n  \"), \"\\n    \")), mdx(\"h1\", {\n    \"id\": \"creating-a-consumer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Creating a Consumer\"), mdx(\"h2\", {\n    \"id\": \"in-rust\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"In [\", mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"rust\",\n    \"title\": \"Rust\"\n  }), \"rust\"), \"]\"), mdx(\"p\", null, \"Crate : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://crates.io/crates/kafka\"\n  }), \"kafka\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-Rust\"\n  }), \"use kafka::consumer::{Consumer, FetchOffset, GroupOffsetStorage};\\nlet mut consumer =\\n   Consumer::from_hosts(vec!(\\\"localhost:9092\\\".to_owned()))\\n      .with_topic_partitions(\\\"my-topic\\\".to_owned(), &[0, 1])\\n      .with_fallback_offset(FetchOffset::Earliest)\\n      .with_group(\\\"my-group\\\".to_owned())\\n      .with_offset_storage(GroupOffsetStorage::Kafka)\\n      .create()\\n      .unwrap();\\nloop {\\n  for ms in consumer.poll().unwrap().iter() {\\n    for m in ms.messages() {\\n      println!(\\\"{:?}\\\", m);\\n    }\\n    consumer.consume_messageset(ms);\\n  }\\n  consumer.commit_consumed().unwrap();\\n}\\n\")), mdx(\"p\", null, \"Crate : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://crates.io/crates/rdkafka\"\n  }), \"rdkafka\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-Rust\"\n  }), \"async fn consume(brokers: &str, group_id: &str, topics: &[&str]) {\\n    let context = CustomContext;\\n\\n    let consumer: LoggingConsumer = ClientConfig::new()\\n        .set(\\\"group.id\\\", group_id)\\n        .set(\\\"bootstrap.servers\\\", brokers)\\n        .set(\\\"enable.partition.eof\\\", \\\"false\\\")\\n        .set(\\\"session.timeout.ms\\\", \\\"6000\\\")\\n        .set(\\\"enable.auto.commit\\\", \\\"true\\\")\\n        //.set(\\\"statistics.interval.ms\\\", \\\"30000\\\")\\n        //.set(\\\"auto.offset.reset\\\", \\\"smallest\\\")\\n        .set_log_level(RDKafkaLogLevel::Debug)\\n        .create_with_context(context)\\n        .expect(\\\"Consumer creation failed\\\");\\n\\n    consumer\\n        .subscribe(&topics.to_vec())\\n        .expect(\\\"Can't subscribe to specified topics\\\");\\n\\n    // consumer.start() returns a stream. The stream can be used ot chain together expensive steps,\\n    // such as complex computations on a thread pool or asynchronous IO.\\n    let mut message_stream = consumer.start();\\n\\n    while let Some(message) = message_stream.next().await {\\n        match message {\\n            Err(e) => warn!(\\\"Kafka error: {}\\\", e),\\n            Ok(m) => {\\n                let payload = match m.payload_view::<str>() {\\n                    None => \\\"\\\",\\n                    Some(Ok(s)) => s,\\n                    Some(Err(e)) => {\\n                        warn!(\\\"Error while deserializing message payload: {:?}\\\", e);\\n                        \\\"\\\"\\n                    }\\n                };\\n                info!(\\\"key: '{:?}', payload: '{}', topic: {}, partition: {}, offset: {}, timestamp: {:?}\\\",\\n                      m.key(), payload, m.topic(), m.partition(), m.offset(), m.timestamp());\\n                if let Some(headers) = m.headers() {\\n                    for i in 0..headers.count() {\\n                        let header = headers.get(i).unwrap();\\n                        info!(\\\"  Header {:#?}: {:?}\\\", header.0, header.1);\\n                    }\\n                }\\n                consumer.commit_message(&m, CommitMode::Async).unwrap();\\n            }\\n        };\\n    }\\n}\\n\")), mdx(\"hr\", null), mdx(\"h2\", {\n    \"id\": \"in-golang\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"In [\", mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"golang\",\n    \"title\": \"Golang\"\n  }), \"golang\"), \"]\"), mdx(\"p\", null, \"Package : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/confluentinc/confluent-kafka-go\"\n  }), \"Confluent Inc\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-golang\"\n  }), \"func main() {\\n\\n    c, err := kafka.NewConsumer(&kafka.ConfigMap{\\n        \\\"bootstrap.servers\\\": \\\"localhost\\\",\\n        \\\"group.id\\\":          \\\"myGroup\\\",\\n        \\\"auto.offset.reset\\\": \\\"earliest\\\",\\n    })\\n\\n    if err != nil {\\n        panic(err)\\n    }\\n\\n    c.SubscribeTopics([]string{\\\"myTopic\\\", \\\"^aRegex.*[Tt]opic\\\"}, nil)\\n\\n    for {\\n        msg, err := c.ReadMessage(-1)\\n        if err == nil {\\n            fmt.Printf(\\\"Message on %s: %s\\\\n\\\", msg.TopicPartition, string(msg.Value))\\n        } else {\\n            // The client will automatically try to recover from all errors.\\n            fmt.Printf(\\\"Consumer error: %v (%v)\\\\n\\\", err, msg)\\n        }\\n    }\\n\\n    c.Close()\\n}\\n\")), mdx(\"h2\", {\n    \"id\": \"package--segmentio\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Package : \", mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"https://github.com/segmentio/kafka-go\"\n  }), \"SegmentIO\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-golang\"\n  }), \"func consumer(){}\\nr := kafka.NewReader(kafka.ReaderConfig{\\n    Brokers:   []string{\\\"localhost:9092\\\"},\\n    Topic:     \\\"topic-A\\\",\\n    Partition: 0,\\n    MinBytes:  10e3, // 10KB\\n    MaxBytes:  10e6, // 10MB\\n})\\nr.SetOffset(42)\\n\\nfor {\\n    m, err := r.ReadMessage(context.Background())\\n    if err != nil {\\n        break\\n    }\\n    fmt.Printf(\\\"message at offset %d: %s = %s\\\\n\\\", m.Offset, string(m.Key), string(m.Value))\\n}\\n\\nr.Close()\\n}\\n\")), mdx(\"p\", null, \"Package : \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/Shopify/sarama\"\n  }), \"Sarama\")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-golang\"\n  }), \"// ConsumeClaim must start a consumer loop of ConsumerGroupClaim's Messages().\\nfunc (consumer *Consumer) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {\\n\\n    // NOTE:\\n    // Do not move the code below to a goroutine.\\n    // The `ConsumeClaim` itself is called within a goroutine, see:\\n    // https://github.com/Shopify/sarama/blob/master/consumer_group.go#L27-L29\\n    for message := range claim.Messages() {\\n        log.Printf(\\\"Message claimed: value = %s, timestamp = %v, topic = %s\\\", string(message.Value), message.Timestamp, message.Topic)\\n        session.MarkMessage(message, \\\"\\\")\\n    }\\n\\n    return nil\\n}\\n\\ngo func() comsumer{\\n        defer wg.Done()\\n        for {\\n            // `Consume` should be called inside an infinite loop, when a\\n            // server-side rebalance happens, the consumer session will need to be\\n            // recreated to get the new claims\\n            if err := client.Consume(ctx, strings.Split(topics, \\\",\\\"), &consumer); err != nil {\\n                log.Panicf(\\\"Error from consumer: %v\\\", err)\\n            }\\n            // check if context was cancelled, signaling that the consumer should stop\\n            if ctx.Err() != nil {\\n                return\\n            }\\n            consumer.ready = make(chan bool)\\n        }\\n    }()\\n\\n\")), mdx(\"h1\", {\n    \"id\": \"commits\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, \"Commits\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Consumers use kafka to track their position in each partition\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"commit\"), \" act of updating current position in kafka\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"message \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"__consumer_offsets\"), \" topic with the offset for each partition\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"when rebalance each consumer receives a new partition and obtains the latest committed offset from where to start reading\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Commit Strategy\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Automatic\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Done by consumer every 5 seconds configurable\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Commits largest offset from \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"poll\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"call to \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"poll\"), \" will always commit the last offset\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"results in double processing if \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"rebalance\"), \" occurs in between a 5 sec window\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Commit Current Offset\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Gives control to the developer\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"commitSync\"), \" triggers commit of the last offset returned by \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"poll\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"must be called after processing all messages\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Synchronous call blocks the application\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Auto retry till success of non retry-able failure\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Asynchronous Commit\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Fire and forget till we get a callback\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Does not auto retry as a later commit request might have latest Offset\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Async + Sync Commit\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"CommitAsync\"), \" always\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Trigger a CommitSync just before exit\")))))));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"a9f33b82-4aa7-599b-a242-54db28ac76f1","fields":{"slug":"/consumer","title":"Consumer"}}}]},"fields":{"slug":"/rust","title":"Rust"}}},"pageContext":{"id":"80160a7b-29c9-59fa-866f-c39ebab1da04"}},"staticQueryHashes":["2098632890","426988268"]}